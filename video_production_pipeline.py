#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ULTIMATE VIDEO PRODUCTION PIPELINE v2.0
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å —Ü–≤–µ—Ç–Ω—ã–º–∏ —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏ –∏ —Ç–æ—á–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π
–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç: —Å–ª–∞–π–¥—à–æ—É + –æ–∑–≤—É—á–∫–∞ + —Å—É–±—Ç–∏—Ç—Ä—ã = –≥–æ—Ç–æ–≤–æ–µ –≤–∏–¥–µ–æ
"""

import os
import sys
import json
import time
import math
import random
import asyncio
import threading
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue
import logging

# GUI imports
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

# Core processing imports
import cv2
import numpy as np
import whisper
import edge_tts

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MotionEffects:
    """–ü–ª–∞–≤–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –¥–≤–∏–∂–µ–Ω–∏—è –¥–ª—è —Å–ª–∞–π–¥—à–æ—É"""
    
    @staticmethod
    def ease_in_out_sine(t: float) -> float:
        return -(math.cos(math.pi * t) - 1) / 2
    
    @staticmethod
    def ease_in_out_cubic(t: float) -> float:
        if t < 0.5:
            return 4 * t * t * t
        return 1 - pow(-2 * t + 2, 3) / 2
    
    @staticmethod
    def ease_in_out_quart(t: float) -> float:
        if t < 0.5:
            return 8 * t * t * t * t
        return 1 - pow(-2 * t + 2, 4) / 2

class HighQualityImageProcessor:
    """–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self, width=1920, height=1080, quality_mode="high"):
        self.width = width
        self.height = height
        
        # –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        if quality_mode == "high":
            self.quality_reduction = 0.6  # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            self.blur_radius = 30         # –ë–æ–ª—å—à–µ –±–ª—é—Ä–∞ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
        else:  # fast mode
            self.quality_reduction = 0.3
            self.blur_radius = 2
        
        # CUDA support
        self.cuda_available = False
        try:
            self.cuda_available = cv2.cuda.getCudaEnabledDeviceCount() > 0
            if self.cuda_available:
                logger.info("‚úÖ CUDA acceleration enabled")
        except:
            logger.info("‚ÑπÔ∏è Using CPU processing")
    
    def load_image_files(self, img_folder: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ø–∞–ø–∫–∏"""
        extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.gif'}
        
        image_files = []
        for ext in extensions:
            image_files.extend(img_folder.glob(f'*{ext}'))
            image_files.extend(img_folder.glob(f'*{ext.upper()}'))
        
        return sorted([str(f) for f in image_files])
    
    def extend_image_list(self, image_files: list, target_duration: float, fps: int = 30):
        """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        total_frames_needed = int(target_duration * fps)
        slides_needed = max(10, total_frames_needed // (fps * 8))  # –ú–∏–Ω–∏–º—É–º 10 —Å–ª–∞–π–¥–æ–≤, 8 —Å–µ–∫ –Ω–∞ —Å–ª–∞–π–¥
        
        if len(image_files) >= slides_needed:
            return image_files[:slides_needed]
        
        # –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –Ω–æ–≤–æ–º –ø–æ—Ä—è–¥–∫–µ
        extended_list = []
        original_count = len(image_files)
        
        for i in range(slides_needed):
            if i < original_count:
                extended_list.append(image_files[i])
            else:
                # –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤ —Å–ª—É—á–∞–π–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                random_index = random.randint(0, original_count - 1)
                extended_list.append(image_files[random_index])
        
        return extended_list
    
    def preprocess_image(self, image_path: str):
        """–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            img = cv2.imread(image_path, cv2.IMREAD_COLOR)
            if img is None:
                return None
            
            # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞
            height, width = img.shape[:2]
            new_width = int(width * self.quality_reduction)
            new_height = int(height * self.quality_reduction)
            
            img_resized = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
            
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π –±–ª—é—Ä –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
            if self.blur_radius > 0:
                kernel_size = self.blur_radius * 2 + 1
                img_resized = cv2.GaussianBlur(img_resized, (kernel_size, kernel_size), 0)
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ª—É—á—à–µ–π –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π
            img_final = cv2.resize(img_resized, (self.width, self.height), interpolation=cv2.INTER_CUBIC)
            
            return img_final
            
        except Exception as e:
            logger.error(f"Error processing {image_path}: {e}")
            return None
    
    def apply_motion_effect(self, img, effect_type: str, progress: float):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–ª–∞–≤–Ω—ã—Ö –∑—É–º-—ç—Ñ—Ñ–µ–∫—Ç–æ–≤ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
        height, width = img.shape[:2]
        smooth_progress = MotionEffects.ease_in_out_sine(progress)
        
        # –£—Å–∫–æ—Ä–µ–Ω–Ω—ã–π –∑—É–º —Å –ø–ª–∞–≤–Ω—ã–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞–º–∏
        max_zoom = 0.4
        zoom_curve = math.sin(smooth_progress * math.pi)
        scale = 1.0 + max_zoom * zoom_curve
        
        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –∑—É–º–æ–≤
        centers = {
            "zoom_center": (width // 2, height // 2),
            "zoom_left": (width // 3, height // 2),
            "zoom_right": (width * 2 // 3, height // 2),
            "zoom_top": (width // 2, height // 3),
            "zoom_bottom": (width // 2, height * 2 // 3),
            "zoom_top_left": (width // 4, height // 4),
            "zoom_top_right": (width * 3 // 4, height // 4),
            "zoom_bottom_left": (width // 4, height * 3 // 4),
            "zoom_bottom_right": (width * 3 // 4, height * 3 // 4),
        }
        
        if effect_type == "static":
            breathing = 0.02 * math.sin(smooth_progress * math.pi * 2)
            scale = 1.0 + breathing
            center_x, center_y = width // 2, height // 2
        else:
            center_x, center_y = centers.get(effect_type, (width // 2, height // 2))
        
        M = cv2.getRotationMatrix2D((center_x, center_y), 0, scale)
        
        try:
            if self.cuda_available:
                gpu_img = cv2.cuda_GpuMat()
                gpu_img.upload(img)
                gpu_result = cv2.cuda.warpAffine(gpu_img, M, (width, height), 
                                               flags=cv2.INTER_CUBIC | cv2.WARP_FILL_OUTLIERS)
                result = gpu_result.download()
            else:
                result = cv2.warpAffine(img, M, (width, height), 
                                      flags=cv2.INTER_CUBIC | cv2.WARP_FILL_OUTLIERS)
        except:
            result = cv2.warpAffine(img, M, (width, height), flags=cv2.INTER_CUBIC)
        
        return result
    
    def create_transition_frames(self, img1, img2, transition_frames: int):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–ª–∞–≤–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤"""
        frames = []
        
        for i in range(transition_frames):
            alpha = i / (transition_frames - 1) if transition_frames > 1 else 0
            smooth_alpha = MotionEffects.ease_in_out_quart(alpha)
            
            blended = cv2.addWeighted(img1, 1 - smooth_alpha, img2, smooth_alpha, 0)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∞
            if transition_frames > 10 and i in range(transition_frames//3, 2*transition_frames//3):
                blended = cv2.GaussianBlur(blended, (3, 3), 0)
            
            frames.append(blended)
        
        return frames

class EnhancedTTSProcessor:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å"""
    
    def __init__(self):
        self.voices = {
            'en': {
                'aria': 'en-US-AriaNeural',
                'jenny': 'en-US-JennyNeural',
                'michelle': 'en-US-MichelleNeural',
                'ana': 'en-US-AnaNeural',
                'emma': 'en-GB-SoniaNeural',
                'libby': 'en-GB-LibbyNeural',
                'mia': 'en-GB-MiaNeural',
            },
            'es': {
                'elvira': 'es-ES-ElviraNeural',
                'abril': 'es-ES-AbrilNeural',
                'delfina': 'es-MX-DaliaNeural',
                'renata': 'es-MX-RenataNeural',
                'sofia': 'es-CO-SalomeNeural',
                'ximena': 'es-CO-XimenaNeural',
                'camila': 'es-AR-ElenaNeural',
            }
        }
    
    def detect_language(self, text: str) -> str:
        """–ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞"""
        sample = text[:200].lower()
        
        # –ò—Å–ø–∞–Ω—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        spanish_chars = ['√±', '√°', '√©', '√≠', '√≥', '√∫', '¬ø', '¬°']
        spanish_words = ['el', 'la', 'de', 'que', 'y', 'es', 'en', 'un', 'se', 'no', 
                        'te', 'lo', 'le', 'da', 'su', 'por', 'son', 'con', 'para', 
                        'del', 'los', 'las', 'una', 'este', 'esta']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–∏–π
        if any(char in sample for char in spanish_chars):
            return 'es'
        
        words = sample.split()
        spanish_score = sum(1 for word in words if word in spanish_words)
        if spanish_score > len(words) * 0.25:
            return 'es'
        
        return 'en'
    
    async def text_to_speech(self, text: str, output_file: Path, config: dict):
        """–í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏"""
        language = self.detect_language(text)
        voice_key = config['voices'][language]
        voice_name = self.voices[language][voice_key]
        
        # –°–∫–æ—Ä–æ—Å—Ç—å –≤ Edge TTS —Ñ–æ—Ä–º–∞—Ç–µ
        speed_percent = int((config['speed'] - 1) * 100)
        rate_param = f"+{speed_percent}%" if speed_percent >= 0 else f"{speed_percent}%"
        
        logger.info(f"üé§ Generating speech: {language} - {voice_key} - {rate_param}")
        
        communicate = edge_tts.Communicate(
            text=text,
            voice=voice_name,
            rate=rate_param
        )
        await communicate.save(str(output_file))
        
        return output_file

class AdvancedSlideshowGenerator:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–ª–∞–π–¥—à–æ—É"""
    
    def __init__(self, config: dict):
        self.motion_effects = [
            "zoom_center", "zoom_left", "zoom_right", "zoom_top", "zoom_bottom",
            "zoom_top_left", "zoom_top_right", "zoom_bottom_left", "zoom_bottom_right", "static"
        ]
        self.processor = HighQualityImageProcessor(quality_mode=config.get('image_quality', 'high'))
    
    def get_audio_duration(self, audio_file: Path) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        try:
            result = subprocess.run([
                'ffprobe', '-i', str(audio_file), '-show_entries', 'format=duration',
                '-v', 'quiet', '-of', 'csv=p=0'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                return float(result.stdout.strip())
        except:
            pass
        
        return 300.0  # Fallback: 5 –º–∏–Ω—É—Ç
    
    def create_slideshow(self, img_folder: Path, output_file: Path, target_duration: float, 
                        progress_callback=None):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ª–∞–π–¥—à–æ—É"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_files = self.processor.load_image_files(img_folder)
            if not image_files:
                raise Exception("No images found")
            
            # –†–∞—Å—à–∏—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–¥ –Ω—É–∂–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            extended_images = self.processor.extend_image_list(image_files, target_duration)
            
            if progress_callback:
                progress_callback("üñºÔ∏è Preprocessing images with high quality...")
            
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            processed_images = []
            with ThreadPoolExecutor(max_workers=4) as executor:
                futures = [executor.submit(self.processor.preprocess_image, img_path) 
                          for img_path in extended_images]
                
                for future in as_completed(futures):
                    img = future.result()
                    if img is not None:
                        processed_images.append(img)
            
            if not processed_images:
                raise Exception("Failed to process images")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–µ–æ
            fps = 30
            width, height = 1920, 1080
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(output_file), fourcc, fps, (width, height))
            
            if not out.isOpened():
                raise Exception("Failed to create video writer")
            
            total_frames = int(target_duration * fps)
            frames_per_slide = total_frames // len(processed_images)
            
            if progress_callback:
                progress_callback("üé¨ Creating high-quality slideshow...")
            
            frame_count = 0
            for i, img in enumerate(processed_images):
                if frame_count >= total_frames:
                    break
                
                effect_type = random.choice(self.motion_effects)
                
                # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–∞–¥—Ä—ã —Å–ª–∞–π–¥–∞
                for frame_num in range(frames_per_slide):
                    if frame_count >= total_frames:
                        break
                    
                    progress = frame_num / max(frames_per_slide - 1, 1)
                    frame = self.processor.apply_motion_effect(img, effect_type, progress)
                    out.write(frame)
                    frame_count += 1
                    
                    if progress_callback and frame_count % (fps * 5) == 0:  # Update every 5 seconds
                        percent = (frame_count / total_frames) * 100
                        progress_callback(f"üé¨ Creating slideshow: {percent:.1f}%")
                
                # –ü–ª–∞–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Å–ª–∞–π–¥–∞–º–∏
                if i < len(processed_images) - 1 and frame_count < total_frames:
                    next_img = processed_images[i + 1]
                    next_effect = random.choice(self.motion_effects)
                    
                    # –ü–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–¥—Ä —Ç–µ–∫—É—â–µ–≥–æ —Å–ª–∞–π–¥–∞
                    final_frame = self.processor.apply_motion_effect(img, effect_type, 1.0)
                    # –ü–µ—Ä–≤—ã–π –∫–∞–¥—Ä —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–∞–π–¥–∞  
                    initial_next_frame = self.processor.apply_motion_effect(next_img, next_effect, 0.0)
                    
                    # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–≤–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥
                    transition_frames = int(1.2 * fps)
                    transitions = self.processor.create_transition_frames(
                        final_frame, initial_next_frame, transition_frames)
                    
                    for frame in transitions:
                        if frame_count >= total_frames:
                            break
                        out.write(frame)
                        frame_count += 1
            
            out.release()
            logger.info(f"‚úÖ High-quality slideshow created: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Slideshow creation failed: {e}")
            return False

class PrecisionVideoMerger:
    """–í—ã—Å–æ–∫–æ—Ç–æ—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ –∏ —Ü–≤–µ—Ç–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤"""
    
    def __init__(self):
        self.check_ffmpeg()
    
    def check_ffmpeg(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ FFmpeg"""
        try:
            result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
            if result.returncode != 0:
                raise Exception("FFmpeg not working")
            logger.info("‚úÖ FFmpeg ready")
        except Exception as e:
            logger.error("‚ùå FFmpeg not found. Download from https://ffmpeg.org/")
            raise
    
    def merge_video_audio(self, video_file: Path, audio_file: Path, output_file: Path):
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ —Å —Ç–æ—á–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π"""
        cmd = [
            'ffmpeg', '-i', str(video_file), '-i', str(audio_file),
            '-c:v', 'copy', '-c:a', 'aac', '-b:a', '128k',
            '-map', '0:v:0', '-map', '1:a:0',
            '-avoid_negative_ts', 'make_zero',
            '-async', '1',  # —É–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
            '-y', str(output_file)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0
    
    def extract_audio_from_merged_video(self, video_path: Path, audio_output_path: Path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ –¥–ª—è —Ç–æ—á–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        try:
            logger.info(f"üéµ Extracting audio from merged video: {video_path.name}")
            
            cmd = [
                'ffmpeg', '-i', str(video_path),
                '-vn',  # –±–µ–∑ –≤–∏–¥–µ–æ
                '-acodec', 'pcm_s16le',  # –Ω–µ—Å–∂–∞—Ç—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Whisper
                '-ar', '16000',  # —á–∞—Å—Ç–æ—Ç–∞ –¥–ª—è Whisper
                '-ac', '1',      # –º–æ–Ω–æ
                '-y', str(audio_output_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("‚úÖ Audio extracted from merged video")
                return True
            else:
                logger.error(f"‚ùå Audio extraction error: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Audio extraction failed: {e}")
            return False
    
    def generate_colored_subtitles(self, audio_file: Path, subtitle_file: Path, config: dict):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–≤–µ—Ç–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å word-level timestamps"""
        try:
            logger.info("ü§ñ Loading Whisper model...")
            model = whisper.load_model("base")
            
            logger.info("üé§ Transcribing with word-level timestamps...")
            result = model.transcribe(
                str(audio_file), 
                fp16=False, 
                verbose=False,
                word_timestamps=True  # –í–∫–ª—é—á–∞–µ–º word-level timestamps
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ASS —Å —Ü–≤–µ—Ç–∞–º–∏
            ass_content = self.whisper_to_colored_ass(result, config)
            
            with open(subtitle_file, 'w', encoding='utf-8') as f:
                f.write(ass_content)
            
            logger.info(f"‚úÖ Colored subtitles generated: {subtitle_file}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Subtitle generation failed: {e}")
            return False
    
    def whisper_to_colored_ass(self, result, config: dict):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ASS —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏"""
        # –ü–æ–ª—É—á–∞–µ–º —Ü–≤–µ—Ç–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        primary_color = config.get('subtitle_colors', {}).get('primary', '&H00FFFF&')    # –∂–µ–ª—Ç—ã–π
        secondary_color = config.get('subtitle_colors', {}).get('secondary', '&HFFFFFF&') # –±–µ–ª—ã–π
        
        # ASS –∑–∞–≥–æ–ª–æ–≤–æ–∫
        ass_content = """[Script Info]
Title: Generated Colored Subtitles
ScriptType: v4.00+

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial Black,28,&Hffffff,&Hffffff,&H000000,&H80000000,1,0,0,0,100,100,0,0,1,3,2,5,10,10,40,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text

"""
        
        subtitle_offset = config.get('subtitle_offset', 0.0)
        
        for segment in result['segments']:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º word-level –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
            if 'words' in segment and segment['words']:
                words = segment['words']
                word_chunks = self.group_words_into_chunks(words, max_words=4)
                
                for chunk in word_chunks:
                    if not chunk:
                        continue
                    
                    start_time = chunk[0]['start'] + subtitle_offset
                    end_time = chunk[-1]['end'] + subtitle_offset
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å —á–µ—Ä–µ–¥—É—é—â–∏–º–∏—Å—è —Ü–≤–µ—Ç–∞–º–∏
                    text = self.format_colored_text(chunk, primary_color, secondary_color)
                    
                    if text.strip():
                        start_ass = self.seconds_to_ass_time(max(0, start_time))
                        end_ass = self.seconds_to_ass_time(max(0.1, end_time))
                        
                        ass_content += f"Dialogue: 0,{start_ass},{end_ass},Default,,0,0,0,,{text}\n"
            
            else:
                # Fallback –∫ —Å–µ–≥–º–µ–Ω—Ç–∞–º –±–µ–∑ word-level –¥–∞–Ω–Ω—ã—Ö
                start_time = segment['start'] + subtitle_offset
                end_time = segment['end'] + subtitle_offset
                text = segment['text'].strip()
                
                if text:
                    formatted_text = self.format_colored_text_from_string(
                        text, primary_color, secondary_color)
                    start_ass = self.seconds_to_ass_time(max(0, start_time))
                    end_ass = self.seconds_to_ass_time(max(0.1, end_time))
                    
                    ass_content += f"Dialogue: 0,{start_ass},{end_ass},Default,,0,0,0,,{formatted_text}\n"
        
        return ass_content
    
    def format_colored_text(self, word_chunk, primary_color, secondary_color):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å —á–µ—Ä–µ–¥—É—é—â–∏–º–∏—Å—è —Ü–≤–µ—Ç–∞–º–∏"""
        formatted_words = []
        
        for i, word_data in enumerate(word_chunk):
            word = word_data['word'].strip().upper()
            
            if i % 2 == 0:  # —á–µ—Ç–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ - –ø–µ—Ä–≤—ã–π —Ü–≤–µ—Ç
                formatted_words.append(f"{{\\c{primary_color}}}{word}{{\\r}}")
            else:  # –Ω–µ—á–µ—Ç–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ - –≤—Ç–æ—Ä–æ–π —Ü–≤–µ—Ç
                formatted_words.append(f"{{\\c{secondary_color}}}{word}{{\\r}}")
        
        return " ".join(formatted_words)
    
    def format_colored_text_from_string(self, text, primary_color, secondary_color):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å —á–µ—Ä–µ–¥—É—é—â–∏–º–∏—Å—è —Ü–≤–µ—Ç–∞–º–∏"""
        words = text.strip().split()
        formatted_words = []
        
        for i, word in enumerate(words):
            word = word.upper()
            
            if i % 2 == 0:  # —á–µ—Ç–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ - –ø–µ—Ä–≤—ã–π —Ü–≤–µ—Ç
                formatted_words.append(f"{{\\c{primary_color}}}{word}{{\\r}}")
            else:  # –Ω–µ—á–µ—Ç–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ - –≤—Ç–æ—Ä–æ–π —Ü–≤–µ—Ç
                formatted_words.append(f"{{\\c{secondary_color}}}{word}{{\\r}}")
        
        return " ".join(formatted_words)
    
    def group_words_into_chunks(self, words, max_words=4):
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–ª–æ–≤ –≤ —á–∞–Ω–∫–∏"""
        chunks = []
        current_chunk = []
        
        for word in words:
            current_chunk.append(word)
            
            if len(current_chunk) >= max_words:
                chunks.append(current_chunk)
                current_chunk = []
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
    
    def seconds_to_ass_time(self, seconds):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–µ–∫—É–Ω–¥ –≤ ASS —Ñ–æ—Ä–º–∞—Ç"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        centisecs = int((seconds % 1) * 100)
        
        return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"
    
    def add_colored_subtitles_to_video(self, video_file: Path, subtitle_file: Path, output_file: Path):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –∫ –≤–∏–¥–µ–æ"""
        subtitle_path_escaped = str(subtitle_file).replace('\\', '\\\\').replace(':', '\\:')
        
        cmd = [
            'ffmpeg', '-i', str(video_file),
            '-vf', f"ass='{subtitle_path_escaped}'",
            '-c:a', 'copy', '-y', str(output_file)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0

class UltimateVideoProductionPipeline:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –≤–∏–¥–µ–æ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
    
    def __init__(self):
        self.tts_processor = EnhancedTTSProcessor()
        self.video_merger = PrecisionVideoMerger()
        self.progress_callback = None
        
    def find_video_folders(self, root_path: Path):
        """–ü–æ–∏—Å–∫ –≤—Å–µ—Ö –ø–∞–ø–æ–∫ video_X"""
        video_folders = []
        
        for folder in root_path.iterdir():
            if folder.is_dir() and folder.name.startswith('video_'):
                try:
                    num = int(folder.name.split('_')[1])
                    video_folders.append((num, folder))
                except (IndexError, ValueError):
                    continue
        
        video_folders.sort(key=lambda x: x[0])
        return [folder for _, folder in video_folders]
    
    def create_folder_structure(self, video_folder: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫"""
        subfolders = ['img', 'text', 'voice', 'subtitles', 'slideshow', 'output']
        for subfolder in subfolders:
            (video_folder / subfolder).mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π config.json
        config_file = video_folder / 'config.json'
        if not config_file.exists():
            config = {
                'voices': {'en': 'aria', 'es': 'elvira'},
                'speed': 0.95,
                'slideshow_effects': True,
                'subtitle_style': 'colorful',
                'subtitle_offset': 0.0,
                'word_timestamps': True,
                'image_quality': 'high',  # high/fast
                'subtitle_colors': {
                    'primary': '&H00FFFF&',    # –∂–µ–ª—Ç—ã–π
                    'secondary': '&HFFFFFF&'   # –±–µ–ª—ã–π
                },
                'blur_radius': 30,
                'quality_reduction': 0.6
            }
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
    
    def validate_folder(self, video_folder: Path):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞–ø–∫–∏ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        img_folder = video_folder / 'img'
        text_folder = video_folder / 'text'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        processor = HighQualityImageProcessor()
        image_files = processor.load_image_files(img_folder)
        if not image_files:
            return False, "No images found in img/ folder"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        text_files = list(text_folder.glob('*.txt'))
        if not text_files:
            return False, "No text file found in text/ folder"
        
        return True, "OK"
    
    def process_single_video(self, video_folder: Path):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏ video_X —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
        try:
            folder_name = video_folder.name
            logger.info(f"üé¨ Processing: {folder_name}")
            
            if self.progress_callback:
                self.progress_callback(f"üìÅ Processing {folder_name}...")
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
            self.create_folder_structure(video_folder)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            is_valid, error_msg = self.validate_folder(video_folder)
            if not is_valid:
                logger.error(f"‚ùå {folder_name}: {error_msg}")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config_file = video_folder / 'config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
            text_file = next((video_folder / 'text').glob('*.txt'))
            voice_file = video_folder / 'voice' / f'{folder_name}_voice.mp3'
            slideshow_file = video_folder / 'slideshow' / f'{folder_name}_slideshow.mp4'
            subtitle_file = video_folder / 'subtitles' / f'{folder_name}_subtitles.ass'  # ASS —Ñ–æ—Ä–º–∞—Ç
            temp_video = video_folder / 'output' / f'{folder_name}_temp.mp4'
            temp_audio = video_folder / 'output' / f'{folder_name}_temp.wav'
            final_video = video_folder / 'output' / f'{folder_name}_final.mp4'
            
            # –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–∑–≤—É—á–∫–∏
            if self.progress_callback:
                self.progress_callback(f"üé§ {folder_name}: Generating high-quality voice...")
            
            with open(text_file, 'r', encoding='utf-8') as f:
                text_content = f.read().strip()
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                loop.run_until_complete(
                    self.tts_processor.text_to_speech(text_content, voice_file, config)
                )
            finally:
                loop.close()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–∑–≤—É—á–∫–∏
            audio_duration = self.get_audio_duration(voice_file)
            logger.info(f"üìè Audio duration: {audio_duration:.1f} seconds")
            
            # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å–ª–∞–π–¥—à–æ—É
            if self.progress_callback:
                self.progress_callback(f"üé¨ {folder_name}: Creating high-quality slideshow...")
            
            slideshow_gen = AdvancedSlideshowGenerator(config)
            success = slideshow_gen.create_slideshow(
                video_folder / 'img',
                slideshow_file,
                audio_duration,
                lambda msg: self.progress_callback(f"{folder_name}: {msg}") if self.progress_callback else None
            )
            
            if not success:
                logger.error(f"‚ùå Failed to create slideshow for {folder_name}")
                return False
            
            # –®–∞–≥ 3: –¢–æ—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ
            if self.progress_callback:
                self.progress_callback(f"üîó {folder_name}: Precision merging video and audio...")
            
            if not self.video_merger.merge_video_audio(slideshow_file, voice_file, temp_video):
                logger.error(f"‚ùå Failed to merge video and audio for {folder_name}")
                return False
            
            # –®–∞–≥ 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –¥–ª—è —Ç–æ—á–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            if self.progress_callback:
                self.progress_callback(f"üéµ {folder_name}: Extracting audio for precise sync...")
            
            if not self.video_merger.extract_audio_from_merged_video(temp_video, temp_audio):
                logger.error(f"‚ùå Failed to extract audio for {folder_name}")
                return False
            
            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–≤–µ—Ç–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å word-level timestamps
            if self.progress_callback:
                self.progress_callback(f"üåà {folder_name}: Generating colored subtitles...")
            
            if not self.video_merger.generate_colored_subtitles(temp_audio, subtitle_file, config):
                logger.error(f"‚ùå Failed to generate colored subtitles for {folder_name}")
                return False
            
            # –®–∞–≥ 6: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –≤–∏–¥–µ–æ
            if self.progress_callback:
                self.progress_callback(f"‚ú® {folder_name}: Adding colored subtitles...")
            
            if not self.video_merger.add_colored_subtitles_to_video(temp_video, subtitle_file, final_video):
                logger.error(f"‚ùå Failed to add colored subtitles for {folder_name}")
                return False
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if temp_audio.exists():
                temp_audio.unlink()
            
            logger.info(f"‚úÖ {folder_name}: Complete! Final video: {final_video}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Critical error processing {video_folder.name}: {e}")
            return False
    
    def get_audio_duration(self, audio_file: Path) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        try:
            result = subprocess.run([
                'ffprobe', '-i', str(audio_file), '-show_entries', 'format=duration',
                '-v', 'quiet', '-of', 'csv=p=0'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                return float(result.stdout.strip())
        except:
            pass
        
        return 300.0  # Fallback
    
    def process_all_videos(self, root_path: Path, progress_callback=None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –≤–∏–¥–µ–æ –ø–∞–ø–æ–∫ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
        self.progress_callback = progress_callback
        
        video_folders = self.find_video_folders(root_path)
        
        if not video_folders:
            logger.error("‚ùå No video_X folders found")
            return False
        
        logger.info(f"üìÅ Found {len(video_folders)} video folders")
        
        success_count = 0
        total_count = len(video_folders)
        
        for i, video_folder in enumerate(video_folders, 1):
            if progress_callback:
                progress_callback(f"üéØ Processing {i}/{total_count}: {video_folder.name}")
            
            success = self.process_single_video(video_folder)
            if success:
                success_count += 1
            
            overall_progress = (i / total_count) * 100
            if progress_callback:
                progress_callback(f"üìä Overall progress: {overall_progress:.1f}% ({i}/{total_count})")
        
        logger.info(f"üéâ Processing complete! Success: {success_count}/{total_count}")
        return success_count == total_count

class AdvancedVideoProductionGUI:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("üé¨ Ultimate Video Production Pipeline v2.0 - Maximum Quality")
        self.root.geometry("1000x800")
        self.root.resizable(True, True)
        
        self.pipeline = UltimateVideoProductionPipeline()
        self.root_path = tk.StringVar()
        self.is_processing = False
        
        self.create_widgets()
        
    def create_widgets(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        # –ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_label = ttk.Label(main_frame, text="üé¨ Ultimate Video Production Pipeline v2.0", 
                               font=("Arial", 20, "bold"))
        title_label.grid(row=0, column=0, columnspan=3, pady=(0, 10))
        
        subtitle_label = ttk.Label(main_frame, text="üåà High Quality ‚Ä¢ Colored Subtitles ‚Ä¢ Precise Sync", 
                                  font=("Arial", 12, "italic"))
        subtitle_label.grid(row=1, column=0, columnspan=3, pady=(0, 20))
        
        # –í—ã–±–æ—Ä –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏
        folder_frame = ttk.LabelFrame(main_frame, text="üìÅ Root Folder Selection", padding="10")
        folder_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 15))
        
        ttk.Label(folder_frame, text="Select folder containing video_1, video_2, etc.:").grid(row=0, column=0, sticky=tk.W)
        
        path_frame = ttk.Frame(folder_frame)
        path_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(5, 0))
        
        self.path_entry = ttk.Entry(path_frame, textvariable=self.root_path, width=80)
        self.path_entry.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 5))
        
        ttk.Button(path_frame, text="Browse", command=self.browse_folder).grid(row=0, column=1)
        ttk.Button(path_frame, text="Scan", command=self.scan_folders).grid(row=0, column=2, padx=(5, 0))
        
        path_frame.columnconfigure(0, weight=1)
        
        # –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞–ø–æ–∫
        list_frame = ttk.LabelFrame(main_frame, text="üìã Found Video Folders", padding="10")
        list_frame.grid(row=3, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 15))
        
        columns = ('folder', 'images', 'text', 'config', 'status')
        self.folder_tree = ttk.Treeview(list_frame, columns=columns, show='headings', height=10)
        
        self.folder_tree.heading('folder', text='Folder')
        self.folder_tree.heading('images', text='Images')
        self.folder_tree.heading('text', text='Text Files')
        self.folder_tree.heading('config', text='Config')
        self.folder_tree.heading('status', text='Status')
        
        self.folder_tree.column('folder', width=120)
        self.folder_tree.column('images', width=80)
        self.folder_tree.column('text', width=80)
        self.folder_tree.column('config', width=80)
        self.folder_tree.column('status', width=200)
        
        tree_scroll = ttk.Scrollbar(list_frame, orient=tk.VERTICAL, command=self.folder_tree.yview)
        self.folder_tree.configure(yscrollcommand=tree_scroll.set)
        
        self.folder_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        tree_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        list_frame.columnconfigure(0, weight=1)
        list_frame.rowconfigure(0, weight=1)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ—É–Ω–∫—Ü–∏—è—Ö
        info_frame = ttk.LabelFrame(main_frame, text="‚ú® Features", padding="10")
        info_frame.grid(row=4, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 15))
        
        features_text = """üé® High-Quality Processing ‚Ä¢ üåà Colored Subtitles (Yellow/White) ‚Ä¢ ‚ö° Word-Level Timestamps
üîÑ Precise Audio Sync ‚Ä¢ üìè Duration Matching ‚Ä¢ üé¨ Enhanced Motion Effects ‚Ä¢ ‚öôÔ∏è Full Config Control"""
        
        ttk.Label(info_frame, text=features_text, justify=tk.CENTER, 
                 font=("Arial", 10)).grid(row=0, column=0)
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=5, column=0, columnspan=3, pady=(0, 15))
        
        self.start_button = ttk.Button(button_frame, text="üöÄ Start Maximum Quality Production", 
                                      command=self.start_production)
        self.start_button.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(button_frame, text="üîÑ Refresh", command=self.scan_folders).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="üìã View Logs", command=self.show_logs).pack(side=tk.LEFT, padx=(0, 10))
        ttk.Button(button_frame, text="‚öôÔ∏è Config Help", command=self.show_config_help).pack(side=tk.LEFT)
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å
        progress_frame = ttk.LabelFrame(main_frame, text="üìä Progress", padding="10")
        progress_frame.grid(row=6, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.progress_var = tk.StringVar(value="Ready for maximum quality production...")
        self.progress_label = ttk.Label(progress_frame, textvariable=self.progress_var)
        self.progress_label.grid(row=0, column=0, sticky=tk.W)
        
        self.progress_bar = ttk.Progressbar(progress_frame, mode='indeterminate')
        self.progress_bar.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(5, 0))
        
        progress_frame.columnconfigure(0, weight=1)
        
        # –õ–æ–≥–∏
        log_frame = ttk.LabelFrame(main_frame, text="üìù Activity Log", padding="5")
        log_frame.grid(row=7, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.log_text = tk.Text(log_frame, height=10, wrap=tk.WORD)
        log_scroll = ttk.Scrollbar(log_frame, orient=tk.VERTICAL, command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=log_scroll.set)
        
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        log_scroll.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ—Å–æ–≤ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(3, weight=1)
        main_frame.rowconfigure(7, weight=1)
        folder_frame.columnconfigure(0, weight=1)
        
        # –ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        self.add_log("üöÄ Ultimate Video Production Pipeline v2.0 initialized")
        self.add_log("üåà Features: High Quality ‚Ä¢ Colored Subtitles ‚Ä¢ Precise Sync")
        self.add_log("üìÅ Select root folder and click 'Scan' to find video folders")
    
    def browse_folder(self):
        """–í—ã–±–æ—Ä –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–∏"""
        folder = filedialog.askdirectory(title="Select root folder containing video_X folders")
        if folder:
            self.root_path.set(folder)
            self.scan_folders()
    
    def scan_folders(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫ video_X"""
        if not self.root_path.get():
            messagebox.showerror("Error", "Please select a root folder first")
            return
        
        root_path = Path(self.root_path.get())
        if not root_path.exists():
            messagebox.showerror("Error", "Selected folder does not exist")
            return
        
        # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫
        for item in self.folder_tree.get_children():
            self.folder_tree.delete(item)
        
        # –ü–æ–∏—Å–∫ –ø–∞–ø–æ–∫
        video_folders = self.pipeline.find_video_folders(root_path)
        
        if not video_folders:
            self.add_log("‚ùå No video_X folders found in selected directory")
            return
        
        self.add_log(f"üìÅ Found {len(video_folders)} video folders")
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–ø–∏—Å–æ–∫
        for video_folder in video_folders:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
            img_folder = video_folder / 'img'
            text_folder = video_folder / 'text'
            config_file = video_folder / 'config.json'
            
            processor = HighQualityImageProcessor()
            img_count = len(processor.load_image_files(img_folder)) if img_folder.exists() else 0
            text_count = len(list(text_folder.glob('*.txt'))) if text_folder.exists() else 0
            has_config = "‚úÖ" if config_file.exists() else "‚ùå"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            if img_count > 0 and text_count > 0:
                status = "‚úÖ Ready for high-quality processing"
            elif img_count == 0 and text_count == 0:
                status = "‚ùå Missing img & text folders"
            elif img_count == 0:
                status = "‚ùå Missing images"
            elif text_count == 0:
                status = "‚ùå Missing text file"
            else:
                status = "‚ö†Ô∏è Check configuration"
            
            self.folder_tree.insert('', 'end', values=(
                video_folder.name,
                f"{img_count} files",
                f"{text_count} files",
                has_config,
                status
            ))
        
        self.add_log(f"‚úÖ Scan complete: {len(video_folders)} folders ready for processing")
    
    def start_production(self):
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –≤–∏–¥–µ–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞"""
        if self.is_processing:
            messagebox.showwarning("Warning", "Production is already running!")
            return
        
        if not self.root_path.get():
            messagebox.showerror("Error", "Please select a root folder first")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        ready_count = 0
        for item in self.folder_tree.get_children():
            status = self.folder_tree.item(item)['values'][4]
            if "‚úÖ Ready" in status:
                ready_count += 1
        
        if ready_count == 0:
            messagebox.showerror("Error", "No folders are ready for processing!\nMake sure each video_X folder has images and text files.")
            return
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        result = messagebox.askyesno("Confirm Maximum Quality Production", 
                                   f"Start high-quality processing of {ready_count} video folders?\n\n" +
                                   "Features enabled:\n" +
                                   "üé® Enhanced image quality\n" +
                                   "üåà Colored subtitles (Yellow/White)\n" +
                                   "‚ö° Word-level timestamps\n" +
                                   "üîÑ Precise audio synchronization\n\n" +
                                   "This may take a while but will produce the best results...")
        if not result:
            return
        
        self.is_processing = True
        self.start_button.config(text="üîÑ Processing Maximum Quality...", state="disabled")
        self.progress_bar.start()
        
        self.add_log(f"üöÄ Starting maximum quality production of {ready_count} videos...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        def run_production():
            try:
                root_path = Path(self.root_path.get())
                success = self.pipeline.process_all_videos(root_path, self.update_progress)
                
                self.root.after(0, self.production_complete, success)
                
            except Exception as e:
                logger.error(f"Production error: {e}")
                self.root.after(0, self.production_error, str(e))
        
        thread = threading.Thread(target=run_production, daemon=True)
        thread.start()
    
    def update_progress(self, message: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.root.after(0, lambda: self.progress_var.set(message))
        self.root.after(0, lambda: self.add_log(message))
    
    def production_complete(self, success: bool):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞"""
        self.is_processing = False
        self.progress_bar.stop()
        self.start_button.config(text="üöÄ Start Maximum Quality Production", state="normal")
        
        if success:
            self.progress_var.set("üéâ All high-quality videos completed successfully!")
            self.add_log("üéâ Maximum quality production completed successfully!")
            messagebox.showinfo("Success", "All videos have been processed with maximum quality!\n\n" +
                              "Features applied:\n" +
                              "üé® Enhanced image processing\n" +
                              "üåà Colored subtitles with precise timing\n" +
                              "üîÑ Perfect audio synchronization")
        else:
            self.progress_var.set("‚ö†Ô∏è Production completed with some errors")
            self.add_log("‚ö†Ô∏è Production completed with some errors - check logs")
            messagebox.showwarning("Warning", "Production completed but some videos failed.\nCheck the activity log for details.")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫
        self.scan_folders()
    
    def production_error(self, error_msg: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞"""
        self.is_processing = False
        self.progress_bar.stop()
        self.start_button.config(text="üöÄ Start Maximum Quality Production", state="normal")
        self.progress_var.set("‚ùå Production failed")
        self.add_log(f"‚ùå Production failed: {error_msg}")
        messagebox.showerror("Error", f"Production failed:\n{error_msg}")
    
    def show_logs(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ —Å –ª–æ–≥–∞–º–∏"""
        log_window = tk.Toplevel(self.root)
        log_window.title("üìã Detailed Production Logs")
        log_window.geometry("900x700")
        
        log_text = tk.Text(log_window, wrap=tk.WORD, font=("Consolas", 10))
        log_scroll = ttk.Scrollbar(log_window, orient=tk.VERTICAL, command=log_text.yview)
        log_text.configure(yscrollcommand=log_scroll.set)
        
        log_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        log_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ª–æ–≥–∞
        log_content = self.log_text.get(1.0, tk.END)
        log_text.insert(1.0, log_content)
        log_text.config(state=tk.DISABLED)
    
    def show_config_help(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        help_window = tk.Toplevel(self.root)
        help_window.title("‚öôÔ∏è Configuration Help")
        help_window.geometry("800x600")
        
        help_text = """
üìÅ CONFIG.JSON STRUCTURE

Each video_X folder automatically gets a config.json file with these settings:

üé§ VOICE SETTINGS:
‚Ä¢ "voices": {"en": "aria", "es": "elvira"} - Voice selection
‚Ä¢ "speed": 0.95 - Speech speed (0.5-2.0)

üé® VISUAL SETTINGS:
‚Ä¢ "image_quality": "high" - Image processing quality
‚Ä¢ "blur_radius": 30 - Motion blur amount
‚Ä¢ "quality_reduction": 0.6 - Image compression balance

üåà SUBTITLE SETTINGS:
‚Ä¢ "subtitle_colors": {
    "primary": "&H00FFFF&",    # Yellow (ASS format)
    "secondary": "&HFFFFFF&"   # White (ASS format)
  }
‚Ä¢ "subtitle_offset": 0.0 - Time shift in seconds (+/-)
‚Ä¢ "word_timestamps": true - Word-level precision

‚öôÔ∏è ADVANCED:
‚Ä¢ "slideshow_effects": true - Enable motion effects
‚Ä¢ "subtitle_style": "colorful" - Subtitle appearance

üí° COLOR CODES (ASS format):
‚Ä¢ "&H0000FF&" - Red
‚Ä¢ "&H00FF00&" - Green  
‚Ä¢ "&H00FFFF&" - Yellow
‚Ä¢ "&HFFFFFF&" - White
‚Ä¢ "&HFF0000&" - Blue
‚Ä¢ "&HFF00FF&" - Magenta
‚Ä¢ "&HFFFF00&" - Cyan

üéØ TIPS:
- Edit config.json in each video_X folder for custom settings
- Restart processing after config changes
- Use negative subtitle_offset if subtitles appear too late
- Higher blur_radius = smoother motion (slower processing)
"""
        
        text_widget = tk.Text(help_window, wrap=tk.WORD, font=("Consolas", 10), padx=10, pady=10)
        scroll_help = ttk.Scrollbar(help_window, orient=tk.VERTICAL, command=text_widget.yview)
        text_widget.configure(yscrollcommand=scroll_help.set)
        
        text_widget.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scroll_help.pack(side=tk.RIGHT, fill=tk.Y)
        
        text_widget.insert(1.0, help_text)
        text_widget.config(state=tk.DISABLED)
    
    def add_log(self, message: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        timestamp = time.strftime("%H:%M:%S")
        log_message = f"[{timestamp}] {message}\n"
        
        self.log_text.insert(tk.END, log_message)
        self.log_text.see(tk.END)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ª–æ–≥–∞
        lines = int(self.log_text.index('end-1c').split('.')[0])
        if lines > 1000:
            self.log_text.delete(1.0, "200.0")
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        try:
            self.root.mainloop()
        except KeyboardInterrupt:
            logger.info("Application interrupted by user")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üé¨ Ultimate Video Production Pipeline v2.0")
    print("üåà Maximum Quality ‚Ä¢ Colored Subtitles ‚Ä¢ Precise Sync")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    try:
        import cv2
        import numpy as np
        import whisper
        import edge_tts
        print("‚úÖ All dependencies found")
    except ImportError as e:
        print(f"‚ùå Missing dependency: {e}")
        print("üì¶ Install required packages:")
        print("pip install opencv-python numpy openai-whisper edge-tts")
        return 1
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ FFmpeg
    try:
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception("FFmpeg not working")
        print("‚úÖ FFmpeg found")
    except:
        print("‚ùå FFmpeg not found!")
        print("üì• Download FFmpeg from: https://ffmpeg.org/download.html")
        print("‚öôÔ∏è Add FFmpeg to your system PATH")
        return 1
    
    print("üöÄ Starting Ultimate Video Production Pipeline v2.0...")
    print("üéØ Features: Enhanced Quality ‚Ä¢ Colored Subtitles ‚Ä¢ Word-Level Sync")
    
    # –ó–∞–ø—É—Å–∫ GUI
    app = AdvancedVideoProductionGUI()
    app.run()
    
    return 0

if __name__ == "__main__":
    sys.exit(main())